# Сервис для построения конспектов лекций

## Стек

- Python 3.10
- Fastapi
- Torch
- Transformers
- Spacy

## Документация 

### swagger

- \<service host\>/docs

## Запуск сервиса

```make build up```

## Мониторинг

### Health-check

Endpoint - /health
Ответ 200

## Алгоритмы и модели

Многие тесты можно найти тут: [tests.ipyvb](/ml_tests/tests.ipynb)

### Модель speach2text

Странно сейчас не пользоваться таким опенсорсным решением как whisper, так как оно показывает лучшую метрику на рынке, а также работает с русскм языком.

model link: https://huggingface.co/openai/whisper-large-v3

### Модель суммаризации

Сейчас в суммаризации рускоязычных текстов одним из новых и хороших (по метрикам) подходов является T5 архитекстура. 
Для суммаризации мы использовали модель FredT5 от SberDevices - это опенсорстная Т5 модель обученная на большом корпусе рускоязычных текстов.

model link: https://huggingface.co/ai-forever/FRED-T5-large

### Модель поиска определений

Поиск определений в тексте - это достаточно нестандартная задача, мы попробовали и Spacy NER и Bert NER и поиск ключевых слов, но все это костыльные решения, которые не позволяют находить полноценные определения, а не просто отдельные слова. Поэтому мы разметили датасет на задачу классификации последовательностей. 


Мы поставили задачу классификации и определяли является ли кусок текста определением или нет.  

Вот скрипт обучения модели: [train.ipyvb](/ml_tests/train_cl.ipynb)

В качетсве предобученной модели мы использовали: https://huggingface.co/DeepPavlov/rubert-base-cased-sentence

### Модель поиска терминов в определениях

Для определения конкретного термина мы использовали ллм, так как для такой небольшой задачи она давала очень хорошие результаты.

Мы использовали: https://huggingface.co/IlyaGusev/saiga_mistral_7b_lora

Но конечно эту задачу также можно дестилировать в более маленькую модель! Это можно отнести к планам дальнейшего развития.
